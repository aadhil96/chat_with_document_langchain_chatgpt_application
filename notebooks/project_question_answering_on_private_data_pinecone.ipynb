{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c13e564",
   "metadata": {},
   "source": [
    "# Project: Question-Answering on Private Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f26757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27be823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pypdf -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f172d095",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install docx2txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92306655",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install wikipedia -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5655db",
   "metadata": {},
   "source": [
    "### Loading Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5405ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading PDF, DOCX and TXT files as LangChain Documents\n",
    "def load_document(file):\n",
    "    import os\n",
    "    name, extension = os.path.splitext(file)\n",
    "\n",
    "    if extension == '.pdf':\n",
    "        from langchain.document_loaders import PyPDFLoader\n",
    "        print(f'Loading {file}')\n",
    "        loader = PyPDFLoader(file)\n",
    "    elif extension == '.docx':\n",
    "        from langchain.document_loaders import Docx2txtLoader\n",
    "        print(f'Loading {file}')\n",
    "        loader = Docx2txtLoader(file)\n",
    "    elif extension == '.txt':\n",
    "        from langchain.document_loaders import TextLoader\n",
    "        loader = TextLoader(file)\n",
    "    else:\n",
    "        print('Document format is not supported!')\n",
    "        return None\n",
    "\n",
    "    data = loader.load()\n",
    "    return data\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4cc1099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wikipedia\n",
    "def load_from_wikipedia(query, lang='en', load_max_docs=2):\n",
    "    from langchain.document_loaders import WikipediaLoader\n",
    "    loader = WikipediaLoader(query=query, lang=lang, load_max_docs=load_max_docs)\n",
    "    data = loader.load()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e167923",
   "metadata": {},
   "source": [
    "### Chunking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "394b9316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(data, chunk_size=256):\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=0)\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    return chunks\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4afe29c",
   "metadata": {},
   "source": [
    "### Calculating Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30543f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_embedding_cost(texts):\n",
    "    import tiktoken\n",
    "    enc = tiktoken.encoding_for_model('text-embedding-ada-002')\n",
    "    total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])\n",
    "    print(f'Total Tokens: {total_tokens}')\n",
    "    print(f'Embedding Cost in USD: {total_tokens / 1000 * 0.0004:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff52d368",
   "metadata": {},
   "source": [
    "### Embedding and Uploading to a Vector Database (Pinecone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc7351e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_or_fetch_embeddings(index_name):\n",
    "    import pinecone\n",
    "    from langchain.vectorstores import Pinecone\n",
    "    from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "    \n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    \n",
    "    pinecone.init(api_key=os.environ.get('PINECONE_API_KEY'), environment=os.environ.get('PINECONE_ENV'))\n",
    "    \n",
    "    if index_name in pinecone.list_indexes():\n",
    "        print(f'Index {index_name} already exists. Loading embeddings ... ', end='')\n",
    "        vector_store = Pinecone.from_existing_index(index_name, embeddings)\n",
    "        print('Ok')\n",
    "    else:\n",
    "        print(f'Creating index {index_name} and embeddings ...', end='')\n",
    "        pinecone.create_index(index_name, dimension=1536, metric='cosine')\n",
    "        vector_store = Pinecone.from_documents(chunks, embeddings, index_name=index_name)\n",
    "        print('Ok')\n",
    "        \n",
    "    return vector_store\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dca64b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_pinecone_index(index_name='all'):\n",
    "    import pinecone\n",
    "    pinecone.init(api_key=os.environ.get('PINECONE_API_KEY'), environment=os.environ.get('PINECONE_ENV'))\n",
    "    \n",
    "    if index_name == 'all':\n",
    "        indexes = pinecone.list_indexes()\n",
    "        print('Deleting all indexes ... ')\n",
    "        for index in indexes:\n",
    "            pinecone.delete_index(index)\n",
    "        print('Ok')\n",
    "    else:\n",
    "        print(f'Deleting index {index_name} ...', end='')\n",
    "        pinecone.delete_index(index_name)\n",
    "        print('Ok')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4791a948",
   "metadata": {},
   "source": [
    "### Asking and Getting Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cac24559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_and_get_answer(vector_store, q):\n",
    "    from langchain.chains import RetrievalQA\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "    llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=1)\n",
    "\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
    "\n",
    "    chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "    \n",
    "    answer = chain.run(q)\n",
    "    return answer\n",
    "    \n",
    "    \n",
    "def ask_with_memory(vector_store, question, chat_history=[]):\n",
    "    from langchain.chains import ConversationalRetrievalChain\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "    \n",
    "    llm = ChatOpenAI(temperature=1)\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
    "    \n",
    "    crc = ConversationalRetrievalChain.from_llm(llm, retriever)\n",
    "    result = crc({'question': question, 'chat_history': chat_history})\n",
    "    chat_history.append((question, result['answer']))\n",
    "    \n",
    "    return result, chat_history\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07445a83",
   "metadata": {},
   "source": [
    "### Running Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f5033e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files/us_constitution.pdf\n",
      "You have 41 pages in your data\n",
      "There are 1137 characters in the page\n"
     ]
    }
   ],
   "source": [
    "data = load_document('files/')\n",
    "# print(data[1].page_content)\n",
    "# print(data[10].metadata)\n",
    "\n",
    "print(f'You have {len(data)} pages in your data')\n",
    "print(f'There are {len(data[20].page_content)} characters in the page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd5d6d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = load_document('files/the_great_gatsby.docx')\n",
    "# print(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a28725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = load_from_wikipedia('GPT-4', 'de')\n",
    "# print(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e62c04a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n"
     ]
    }
   ],
   "source": [
    "chunks = chunk_data(data)\n",
    "print(len(chunks))\n",
    "# print(chunks[10].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a7c1579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 16711\n",
      "Embedding Cost in USD: 0.006684\n"
     ]
    }
   ],
   "source": [
    "print_embedding_cost(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "550313e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting all indexes ... \n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "delete_pinecone_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4daa8d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index askadocument and embeddings ...Ok\n"
     ]
    }
   ],
   "source": [
    "index_name = 'askadocument'\n",
    "vector_store = insert_or_fetch_embeddings(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b13065ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I don't have access to the document you're referring to. Without more information, I can't provide an accurate answer about what the whole document is about.\n"
     ]
    }
   ],
   "source": [
    "q = 'What is the whole document about?'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "728ae405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write Quit or Exit to quit.\n",
      "Question #1: quit\n",
      "Quitting ... bye bye!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "i = 1\n",
    "print('Write Quit or Exit to quit.')\n",
    "while True:\n",
    "    q = input(f'Question #{i}: ')\n",
    "    i = i + 1\n",
    "    if q.lower() in ['quit', 'exit']:\n",
    "        print('Quitting ... bye bye!')\n",
    "        time.sleep(2)\n",
    "        break\n",
    "    \n",
    "    answer = ask_and_get_answer(vector_store, q)\n",
    "    print(f'\\nAnswer: {answer}')\n",
    "    print(f'\\n {\"-\" * 50} \\n')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "145d42a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting all indexes ... \n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "delete_pinecone_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a52d645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index chatgpt and embeddings ...Ok\n"
     ]
    }
   ],
   "source": [
    "data = load_from_wikipedia('ChatGPT', 'ro')\n",
    "chunks = chunk_data(data)\n",
    "index_name = 'chatgpt'\n",
    "vector_store = insert_or_fetch_embeddings(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e59f0f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InstructGPT este menționat ca predecesorul lui ChatGPT, însă nu se oferă o descriere detaliată a programului și a capacităților sale.\n"
     ]
    }
   ],
   "source": [
    "# q = \"Ce este ChatGPT?\"\n",
    "q = 'Ce este InstructGPT?'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7fb30ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of September 2021, there are 27 amendments in the U.S. Constitution.\n",
      "[('How many amendments are in the U.S. Constitution?', 'As of September 2021, there are 27 amendments in the U.S. Constitution.')]\n"
     ]
    }
   ],
   "source": [
    "# asking with memory\n",
    "chat_history = []\n",
    "question = 'How many amendments are in the U.S. Constitution?'\n",
    "result, chat_history = ask_with_memory(vector_store, question, chat_history)\n",
    "print(result['answer'])\n",
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4cdcd376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of multiplying the number of amendments in the U.S. Constitution by 2 is not provided in the given context. The original U.S. Constitution had seven articles and twenty-seven amendments have been made since its ratification. Thus, if you multiply twenty-seven amendments by 2, then the result would be 54.\n",
      "[('How many amendments are in the U.S. Constitution?', 'As of September 2021, there are 27 amendments in the U.S. Constitution.'), ('Multiply that number by 2', 'The result of multiplying the number of amendments in the U.S. Constitution by 2 is not provided in the given context. The original U.S. Constitution had seven articles and twenty-seven amendments have been made since its ratification. Thus, if you multiply twenty-seven amendments by 2, then the result would be 54.')]\n"
     ]
    }
   ],
   "source": [
    "question = 'Multiply that number by 2'\n",
    "result, chat_history = ask_with_memory(vector_store, question, chat_history)\n",
    "print(result['answer'])\n",
    "print(chat_history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365d6427",
   "metadata": {},
   "source": [
    "### Ask with Memory Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4039f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "i = 1\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "print(\"Write Quit or Exit to quit\")\n",
    "while True:\n",
    "    q = input(f\"Question #{i}\")\n",
    "    i = i + 1\n",
    "    if q.lower() in [\"quit\",\"exit\"]:\n",
    "        print(\"Qutting\")\n",
    "        time.sleep(2)\n",
    "        break\n",
    "    result, _ = ask_with_memory(vector_store, q, chat_history)\n",
    "    print (result['answer'])\n",
    "    print(\"----------------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
